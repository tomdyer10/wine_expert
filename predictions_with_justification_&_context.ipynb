{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regional_interpretation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10GZyvZEhziGwIROpR725oEGiEcUzdPaC",
      "authorship_tag": "ABX9TyNLW2Swy8q3aOuNvMmAl80v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomdyer10/wine_expert/blob/master/predictions_with_justification_%26_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQdqAGXwBhKL",
        "colab_type": "text"
      },
      "source": [
        "Add token specific interpretation to our wine region classifier and give additional rationale to our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvWtlBaFh_Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *\n",
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ7RV4ogiU-f",
        "colab_type": "text"
      },
      "source": [
        "Mount drive and load databunch + language model databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aud3QILYiJa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('drive/My Drive/wine_reviews', file='data/region_clas_data_lm')\n",
        "data_clas = load_data('drive/My Drive/wine_reviews', file='data/region_clas_data_clas')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqdlCZO4ie02",
        "colab_type": "text"
      },
      "source": [
        "Load learner and load state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKuR9-B1iRwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load('region_classifier/fifth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97tBKUBbvkKk",
        "colab_type": "text"
      },
      "source": [
        "# Redefine FastAI TextClassificationInterp Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JHwftksvuEH",
        "colab_type": "text"
      },
      "source": [
        "Redefining this module here in order to make a few changes to display positive **and** negative influence.\n",
        "\n",
        "Original fast ai code found here - https://github.com/fastai/fastai/blob/master/fastai/text/interpret.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4TrjrGWijok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "def value2rgba(x:float, cmap:Callable=cm.RdYlGn, alpha_mult:float=1.0)->Tuple:\n",
        "    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n",
        "    c = cmap(x)\n",
        "    rgb = (np.array(c[:-1]) * 255).astype(int)\n",
        "    a = c[-1] * alpha_mult\n",
        "    return tuple(rgb.tolist() + [a])\n",
        "\n",
        "def piece_attn_html(pieces:List[str], attns:List[float], sep:str=' ', **kwargs)->str:\n",
        "    html_code,spans = ['<span style=\"font-family: monospace;\">'], []\n",
        "    for p, a in zip(pieces, attns):\n",
        "        p = html.escape(p)\n",
        "        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n",
        "        spans.append(f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>')\n",
        "    html_code.append(sep.join(spans))\n",
        "    html_code.append('</span>')\n",
        "    return ''.join(html_code)\n",
        "\n",
        "def show_piece_attn(*args, **kwargs):\n",
        "    from IPython.display import display, HTML\n",
        "    display(HTML(piece_attn_html(*args, **kwargs)))\n",
        "\n",
        "def _eval_dropouts(mod):\n",
        "        module_name =  mod.__class__.__name__\n",
        "        if 'Dropout' in module_name or 'BatchNorm' in module_name: mod.training = False\n",
        "        for module in mod.children(): _eval_dropouts(module)\n",
        "\n",
        "class TextClassificationInterpretation(ClassificationInterpretation):\n",
        "    \"\"\"Provides an interpretation of classification based on input sensitivity.\n",
        "    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learn: Learner, preds: Tensor, y_true: Tensor, losses: Tensor, ds_type: DatasetType = DatasetType.Valid):\n",
        "        super().__init__(learn,preds,y_true,losses,ds_type)\n",
        "        self.model = learn.model\n",
        "\n",
        "    @classmethod\n",
        "    def from_learner(cls, learn: Learner,  ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None):\n",
        "        \"Gets preds, y_true, losses to construct base class from a learner\"\n",
        "        return cls(learn, *learn.get_preds(ds_type=ds_type, activ=activ, with_loss=True, ordered=True))\n",
        "\n",
        "    def intrinsic_attention(self, text:str, class_id:int=None):\n",
        "        \"\"\"Calculate the intrinsic attention of the input w.r.t to an output `class_id`, or the classification given by the model if `None`.\n",
        "        For reference, see the Sequential Jacobian session at https://www.cs.toronto.edu/~graves/preprint.pdf\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        _eval_dropouts(self.model)\n",
        "        self.model.zero_grad()\n",
        "        self.model.reset()\n",
        "        ids = self.data.one_item(text)[0]\n",
        "        emb = self.model[0].module.encoder(ids).detach().requires_grad_(True)\n",
        "        lstm_output = self.model[0].module(emb, from_embeddings=True)\n",
        "        self.model.eval()\n",
        "        cl = self.model[1](lstm_output + (torch.zeros_like(ids).byte(),))[0].softmax(dim=-1)\n",
        "        if class_id is None: class_id = cl.argmax()\n",
        "        cl[0][class_id].backward()\n",
        "        # removing abs() to also include negative influences\n",
        "        # attn = emb.grad.squeeze().abs().sum(dim=-1)\n",
        "        attn = emb.grad.squeeze().sum(dim=-1)\n",
        "        attn /= attn.max()\n",
        "        tokens = self.data.single_ds.reconstruct(ids[0].cpu())\n",
        "        return tokens, attn\n",
        "\n",
        "    def html_intrinsic_attention(self, text:str, class_id:int=None, **kwargs)->str:\n",
        "        text, attn = self.intrinsic_attention(text, class_id)\n",
        "        return piece_attn_html(text.text.split(), to_np(attn), **kwargs)\n",
        "\n",
        "    def show_intrinsic_attention(self, text:str, class_id:int=None, **kwargs)->None:\n",
        "        text, attn = self.intrinsic_attention(text, class_id)\n",
        "        show_piece_attn(text.text.split(), to_np(attn), **kwargs)\n",
        "\n",
        "    def categorical_top_n(self, k:int, text, class_id:int):\n",
        "        text, attn = self.intrinsic_attention(text, class_id)\n",
        "        print(attn)\n",
        "        top_n = [x for _,x in sorted(zip(attn,text.text.split()), reverse=True)][:k]\n",
        "        scores = [y for y,_ in sorted(zip(attn,text.text.split()), reverse=True)][:k]\n",
        "        return top_n, scores\n",
        "\n",
        "    def show_top_losses(self, k:int, max_len:int=70)->None:\n",
        "        \"\"\"\n",
        "        Create a tabulation showing the first `k` texts in top_losses along with their prediction, actual,loss, and probability of\n",
        "        actual class. `max_len` is the maximum number of tokens displayed.\n",
        "        \"\"\"\n",
        "        from IPython.display import display, HTML\n",
        "        items = []\n",
        "        tl_val,tl_idx = self.top_losses()\n",
        "        for i,idx in enumerate(tl_idx):\n",
        "            if k <= 0: break\n",
        "            k -= 1\n",
        "            tx,cl = self.data.dl(self.ds_type).dataset[idx]\n",
        "            cl = cl.data\n",
        "            classes = self.data.classes\n",
        "            txt = ' '.join(tx.text.split(' ')[:max_len]) if max_len is not None else tx.text\n",
        "            tmp = [txt, f'{classes[self.pred_class[idx]]}', f'{classes[cl]}', f'{self.losses[idx]:.2f}',\n",
        "                   f'{self.preds[idx][cl]:.2f}']\n",
        "            items.append(tmp)\n",
        "        items = np.array(items)\n",
        "        names = ['Text', 'Prediction', 'Actual', 'Loss', 'Probability']\n",
        "        df = pd.DataFrame({n:items[:,i] for i,n in enumerate(names)}, columns=names)\n",
        "        with pd.option_context('display.max_colwidth', pd_max_colwidth()):\n",
        "            display(HTML(df.to_html(index=False)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtgY5ijnwVV5",
        "colab_type": "text"
      },
      "source": [
        "Init interpretation learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFHT40fmjlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_ci = TextClassificationInterpretation.from_learner(learn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9P4Mn2vwgE1",
        "colab_type": "text"
      },
      "source": [
        "Checking data classes for interpretations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqEJ7t_SnqSj",
        "colab_type": "code",
        "outputId": "75b987b9-f710-401a-8560-bf854dec33d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "data_clas.classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['France - Alsace',\n",
              " 'France - Beaujolais',\n",
              " 'France - Bordeaux',\n",
              " 'France - Burgundy',\n",
              " 'France - Champagne',\n",
              " 'France - France Other',\n",
              " 'France - Languedoc-Roussillon',\n",
              " 'France - Loire Valley',\n",
              " 'France - Provence',\n",
              " 'France - Rhône Valley',\n",
              " 'France - Southwest France',\n",
              " 'Italy - Central Italy',\n",
              " 'Italy - Italy Other',\n",
              " 'Italy - Lombardy',\n",
              " 'Italy - Northeastern Italy',\n",
              " 'Italy - Piedmont',\n",
              " 'Italy - Sicily & Sardinia',\n",
              " 'Italy - Southern Italy',\n",
              " 'Italy - Tuscany',\n",
              " 'Italy - Veneto',\n",
              " 'US - California',\n",
              " 'US - Idaho',\n",
              " 'US - Michigan',\n",
              " 'US - New York',\n",
              " 'US - Oregon',\n",
              " 'US - Virginia',\n",
              " 'US - Washington']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpXRa1pAwm0M",
        "colab_type": "text"
      },
      "source": [
        "Show intrinsic attention of test text from our dataset, with respect to category 20 - 'US - California'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "encgKh0yjyPo",
        "colab_type": "code",
        "outputId": "ade59669-0917-47ce-85b3-94e36f2e7326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "text = 'his very fine xxmaj cabernet wants a little time in the cellar . xxmaj right now , it s tight in tannins , with some acidic bitterness in the finish . xxmaj the flavors are of black currants and smoky new oak . xxmaj the xxmaj morisoli xxmaj vineyard has been home to very good , ageable bottlings from the likes of xxmaj sequoia xxmaj grove and xxmaj'\n",
        "txt_ci.show_intrinsic_attention(text, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"-0.003\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxbos</span> <span title=\"-0.023\" style=\"background-color: rgba(165, 0, 38, 0.5);\">his</span> <span title=\"0.120\" style=\"background-color: rgba(220, 58, 43, 0.5);\">very</span> <span title=\"0.619\" style=\"background-color: rgba(207, 234, 132, 0.5);\">fine</span> <span title=\"0.159\" style=\"background-color: rgba(231, 82, 54, 0.5);\">xxmaj</span> <span title=\"0.206\" style=\"background-color: rgba(244, 111, 68, 0.5);\">cabernet</span> <span title=\"0.848\" style=\"background-color: rgba(63, 170, 89, 0.5);\">wants</span> <span title=\"0.194\" style=\"background-color: rgba(241, 104, 64, 0.5);\">a</span> <span title=\"0.574\" style=\"background-color: rgba(225, 242, 151, 0.5);\">little</span> <span title=\"0.136\" style=\"background-color: rgba(224, 68, 48, 0.5);\">time</span> <span title=\"-0.082\" style=\"background-color: rgba(165, 0, 38, 0.5);\">in</span> <span title=\"0.131\" style=\"background-color: rgba(223, 65, 47, 0.5);\">the</span> <span title=\"0.187\" style=\"background-color: rgba(239, 99, 62, 0.5);\">cellar</span> <span title=\"0.043\" style=\"background-color: rgba(186, 20, 38, 0.5);\">.</span> <span title=\"0.034\" style=\"background-color: rgba(180, 15, 38, 0.5);\">xxmaj</span> <span title=\"0.080\" style=\"background-color: rgba(204, 37, 38, 0.5);\">right</span> <span title=\"0.143\" style=\"background-color: rgba(226, 73, 50, 0.5);\">now</span> <span title=\"-0.025\" style=\"background-color: rgba(165, 0, 38, 0.5);\">,</span> <span title=\"-0.036\" style=\"background-color: rgba(165, 0, 38, 0.5);\">it</span> <span title=\"0.392\" style=\"background-color: rgba(253, 220, 135, 0.5);\">s</span> <span title=\"0.368\" style=\"background-color: rgba(253, 208, 125, 0.5);\">tight</span> <span title=\"0.054\" style=\"background-color: rgba(190, 24, 38, 0.5);\">in</span> <span title=\"0.480\" style=\"background-color: rgba(254, 248, 179, 0.5);\">tannins</span> <span title=\"0.085\" style=\"background-color: rgba(206, 39, 38, 0.5);\">,</span> <span title=\"0.238\" style=\"background-color: rgba(247, 134, 78, 0.5);\">with</span> <span title=\"0.210\" style=\"background-color: rgba(244, 114, 69, 0.5);\">some</span> <span title=\"0.089\" style=\"background-color: rgba(208, 41, 38, 0.5);\">acidic</span> <span title=\"0.062\" style=\"background-color: rgba(194, 28, 38, 0.5);\">bitterness</span> <span title=\"0.150\" style=\"background-color: rgba(229, 77, 52, 0.5);\">in</span> <span title=\"0.128\" style=\"background-color: rgba(222, 63, 46, 0.5);\">the</span> <span title=\"0.055\" style=\"background-color: rgba(192, 26, 38, 0.5);\">finish</span> <span title=\"-0.014\" style=\"background-color: rgba(165, 0, 38, 0.5);\">.</span> <span title=\"0.052\" style=\"background-color: rgba(190, 24, 38, 0.5);\">xxmaj</span> <span title=\"-0.038\" style=\"background-color: rgba(165, 0, 38, 0.5);\">the</span> <span title=\"-0.052\" style=\"background-color: rgba(165, 0, 38, 0.5);\">flavors</span> <span title=\"-0.032\" style=\"background-color: rgba(165, 0, 38, 0.5);\">are</span> <span title=\"0.068\" style=\"background-color: rgba(198, 32, 38, 0.5);\">of</span> <span title=\"0.310\" style=\"background-color: rgba(253, 178, 101, 0.5);\">black</span> <span title=\"0.749\" style=\"background-color: rgba(134, 203, 102, 0.5);\">currants</span> <span title=\"0.114\" style=\"background-color: rgba(218, 56, 42, 0.5);\">and</span> <span title=\"0.066\" style=\"background-color: rgba(196, 30, 38, 0.5);\">smoky</span> <span title=\"0.339\" style=\"background-color: rgba(253, 192, 112, 0.5);\">new</span> <span title=\"-0.170\" style=\"background-color: rgba(165, 0, 38, 0.5);\">oak</span> <span title=\"-0.036\" style=\"background-color: rgba(165, 0, 38, 0.5);\">.</span> <span title=\"0.108\" style=\"background-color: rgba(216, 51, 40, 0.5);\">xxmaj</span> <span title=\"0.017\" style=\"background-color: rgba(172, 7, 38, 0.5);\">the</span> <span title=\"-0.045\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-2.377\" style=\"background-color: rgba(165, 0, 38, 0.5);\">morisoli</span> <span title=\"-0.035\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-0.603\" style=\"background-color: rgba(165, 0, 38, 0.5);\">vineyard</span> <span title=\"0.111\" style=\"background-color: rgba(217, 53, 41, 0.5);\">has</span> <span title=\"0.140\" style=\"background-color: rgba(225, 70, 49, 0.5);\">been</span> <span title=\"-0.038\" style=\"background-color: rgba(165, 0, 38, 0.5);\">home</span> <span title=\"0.000\" style=\"background-color: rgba(165, 0, 38, 0.5);\">to</span> <span title=\"0.099\" style=\"background-color: rgba(214, 47, 38, 0.5);\">very</span> <span title=\"0.204\" style=\"background-color: rgba(244, 111, 68, 0.5);\">good</span> <span title=\"0.020\" style=\"background-color: rgba(174, 9, 38, 0.5);\">,</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">ageable</span> <span title=\"0.871\" style=\"background-color: rgba(48, 162, 85, 0.5);\">bottlings</span> <span title=\"0.043\" style=\"background-color: rgba(184, 18, 38, 0.5);\">from</span> <span title=\"0.050\" style=\"background-color: rgba(188, 22, 38, 0.5);\">the</span> <span title=\"-0.242\" style=\"background-color: rgba(165, 0, 38, 0.5);\">likes</span> <span title=\"0.058\" style=\"background-color: rgba(192, 26, 38, 0.5);\">of</span> <span title=\"0.198\" style=\"background-color: rgba(242, 106, 65, 0.5);\">xxmaj</span> <span title=\"0.238\" style=\"background-color: rgba(247, 131, 77, 0.5);\">sequoia</span> <span title=\"-0.039\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-0.083\" style=\"background-color: rgba(165, 0, 38, 0.5);\">grove</span> <span title=\"-0.055\" style=\"background-color: rgba(165, 0, 38, 0.5);\">and</span> <span title=\"-0.296\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSokabcZCZx5",
        "colab_type": "text"
      },
      "source": [
        "# Predict with Justification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voIWqmmMwuom",
        "colab_type": "text"
      },
      "source": [
        "The goal of this code is to act as a helper function that sits on top of the `predict()` function and delivers additional insight.\n",
        "\n",
        "Effectively, we want this to say \"I think this, because...\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbSpRjHCCcmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class justify():\n",
        "  def __init__(self, learner, txt_ci, classes):\n",
        "    self.learner = learner\n",
        "    self.txt_ci = txt_ci\n",
        "    self.classes = classes\n",
        "\n",
        "  def top_k_tokens(self, text, attns, k=5, desc=True):\n",
        "    return [(x, y) for y,x in sorted(zip(attns,text.text.split()), reverse=desc)][:k]\n",
        "\n",
        "  def predict(self, input, k=5, desc=True):\n",
        "    class_pred, pred_idx, pred_conf = self.learner.predict(input)\n",
        "    tokens, attns = self.txt_ci.intrinsic_attention(input, pred_idx)\n",
        "    top_k = self.top_k_tokens(tokens, attns, k, desc)\n",
        "    return (class_pred, pred_conf[pred_idx], top_k)\n",
        "\n",
        "  #give the k nearest categories to actual predictio\n",
        "  def nearest_cat(self, input, k_nearest=1):\n",
        "    class_pred, pred_idx, pred_conf = self.learner.predict(input)\n",
        "    nearest = [x for _,x in sorted(zip(pred_conf, self.classes), reverse=True)][1:(1 + k_nearest)]\n",
        "    if len(nearest) > 1:\n",
        "      nearest_c = []\n",
        "      for n in nearest:\n",
        "        tokens, attns = self.txt_ci.intrinsic_attention(input, self.classes.index(n))\n",
        "        top_k = self.top_k_tokens(tokens, attns, k=5, desc=True)\n",
        "        nearest_c.append((n, pred_conf[self.classes.index(n)], top_k))\n",
        "      return nearest_c\n",
        "    else:\n",
        "      tokens, attns = self.txt_ci.intrinsic_attention(input, self.classes.index(nearest[0]))\n",
        "      top_k = self.top_k_tokens(tokens, attns, k=5, desc=True)\n",
        "      return (nearest, pred_conf[self.classes.index(nearest[0])], top_k)\n",
        "    \n",
        "\n",
        "learn.justify = justify(learn, txt_ci, data_clas.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuI1RljMxKym",
        "colab_type": "text"
      },
      "source": [
        "Demonstrating normal learner prediction output - not very interpretable!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOxfDL1rPPKb",
        "colab_type": "code",
        "outputId": "8f883d84-8c74-413d-d5b4-9b94f5d58443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "learn.predict(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category US - California,\n",
              " tensor(20),\n",
              " tensor([1.6489e-06, 3.1518e-07, 2.2980e-04, 2.0212e-06, 5.1722e-07, 5.7369e-06,\n",
              "         1.6678e-07, 3.7181e-06, 8.7425e-07, 6.0157e-07, 1.6345e-05, 1.3376e-06,\n",
              "         1.2453e-07, 1.5212e-07, 2.0112e-06, 2.6189e-07, 3.0338e-07, 8.4101e-08,\n",
              "         3.5306e-06, 8.7766e-07, 9.9970e-01, 1.4472e-06, 2.5810e-07, 4.0509e-06,\n",
              "         7.0285e-07, 6.3190e-06, 2.0093e-05]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS4HuLfq7yx4",
        "colab_type": "text"
      },
      "source": [
        "show intrinsic attention of demo text with respect to category 0 (France - Alsace)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObI2Wt2vPRnB",
        "colab_type": "code",
        "outputId": "001f6eea-e6bc-47b7-8e4f-2aed0b6d2ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "txt_ci.show_intrinsic_attention(text, 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"-0.003\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxbos</span> <span title=\"-0.023\" style=\"background-color: rgba(165, 0, 38, 0.5);\">his</span> <span title=\"0.120\" style=\"background-color: rgba(220, 58, 43, 0.5);\">very</span> <span title=\"0.619\" style=\"background-color: rgba(207, 234, 132, 0.5);\">fine</span> <span title=\"0.159\" style=\"background-color: rgba(231, 82, 54, 0.5);\">xxmaj</span> <span title=\"0.206\" style=\"background-color: rgba(244, 111, 68, 0.5);\">cabernet</span> <span title=\"0.848\" style=\"background-color: rgba(63, 170, 89, 0.5);\">wants</span> <span title=\"0.194\" style=\"background-color: rgba(241, 104, 64, 0.5);\">a</span> <span title=\"0.574\" style=\"background-color: rgba(225, 242, 151, 0.5);\">little</span> <span title=\"0.136\" style=\"background-color: rgba(224, 68, 48, 0.5);\">time</span> <span title=\"-0.082\" style=\"background-color: rgba(165, 0, 38, 0.5);\">in</span> <span title=\"0.131\" style=\"background-color: rgba(223, 65, 47, 0.5);\">the</span> <span title=\"0.187\" style=\"background-color: rgba(239, 99, 62, 0.5);\">cellar</span> <span title=\"0.043\" style=\"background-color: rgba(186, 20, 38, 0.5);\">.</span> <span title=\"0.034\" style=\"background-color: rgba(180, 15, 38, 0.5);\">xxmaj</span> <span title=\"0.080\" style=\"background-color: rgba(204, 37, 38, 0.5);\">right</span> <span title=\"0.143\" style=\"background-color: rgba(226, 73, 50, 0.5);\">now</span> <span title=\"-0.025\" style=\"background-color: rgba(165, 0, 38, 0.5);\">,</span> <span title=\"-0.036\" style=\"background-color: rgba(165, 0, 38, 0.5);\">it</span> <span title=\"0.392\" style=\"background-color: rgba(253, 220, 135, 0.5);\">s</span> <span title=\"0.368\" style=\"background-color: rgba(253, 208, 125, 0.5);\">tight</span> <span title=\"0.054\" style=\"background-color: rgba(190, 24, 38, 0.5);\">in</span> <span title=\"0.480\" style=\"background-color: rgba(254, 248, 179, 0.5);\">tannins</span> <span title=\"0.085\" style=\"background-color: rgba(206, 39, 38, 0.5);\">,</span> <span title=\"0.238\" style=\"background-color: rgba(247, 134, 78, 0.5);\">with</span> <span title=\"0.210\" style=\"background-color: rgba(244, 114, 69, 0.5);\">some</span> <span title=\"0.089\" style=\"background-color: rgba(208, 41, 38, 0.5);\">acidic</span> <span title=\"0.062\" style=\"background-color: rgba(194, 28, 38, 0.5);\">bitterness</span> <span title=\"0.150\" style=\"background-color: rgba(229, 77, 52, 0.5);\">in</span> <span title=\"0.128\" style=\"background-color: rgba(222, 63, 46, 0.5);\">the</span> <span title=\"0.055\" style=\"background-color: rgba(192, 26, 38, 0.5);\">finish</span> <span title=\"-0.014\" style=\"background-color: rgba(165, 0, 38, 0.5);\">.</span> <span title=\"0.052\" style=\"background-color: rgba(190, 24, 38, 0.5);\">xxmaj</span> <span title=\"-0.038\" style=\"background-color: rgba(165, 0, 38, 0.5);\">the</span> <span title=\"-0.052\" style=\"background-color: rgba(165, 0, 38, 0.5);\">flavors</span> <span title=\"-0.032\" style=\"background-color: rgba(165, 0, 38, 0.5);\">are</span> <span title=\"0.068\" style=\"background-color: rgba(198, 32, 38, 0.5);\">of</span> <span title=\"0.310\" style=\"background-color: rgba(253, 178, 101, 0.5);\">black</span> <span title=\"0.749\" style=\"background-color: rgba(134, 203, 102, 0.5);\">currants</span> <span title=\"0.114\" style=\"background-color: rgba(218, 56, 42, 0.5);\">and</span> <span title=\"0.066\" style=\"background-color: rgba(196, 30, 38, 0.5);\">smoky</span> <span title=\"0.339\" style=\"background-color: rgba(253, 192, 112, 0.5);\">new</span> <span title=\"-0.170\" style=\"background-color: rgba(165, 0, 38, 0.5);\">oak</span> <span title=\"-0.036\" style=\"background-color: rgba(165, 0, 38, 0.5);\">.</span> <span title=\"0.108\" style=\"background-color: rgba(216, 51, 40, 0.5);\">xxmaj</span> <span title=\"0.017\" style=\"background-color: rgba(172, 7, 38, 0.5);\">the</span> <span title=\"-0.045\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-2.377\" style=\"background-color: rgba(165, 0, 38, 0.5);\">morisoli</span> <span title=\"-0.035\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-0.603\" style=\"background-color: rgba(165, 0, 38, 0.5);\">vineyard</span> <span title=\"0.111\" style=\"background-color: rgba(217, 53, 41, 0.5);\">has</span> <span title=\"0.140\" style=\"background-color: rgba(225, 70, 49, 0.5);\">been</span> <span title=\"-0.038\" style=\"background-color: rgba(165, 0, 38, 0.5);\">home</span> <span title=\"0.000\" style=\"background-color: rgba(165, 0, 38, 0.5);\">to</span> <span title=\"0.099\" style=\"background-color: rgba(214, 47, 38, 0.5);\">very</span> <span title=\"0.204\" style=\"background-color: rgba(244, 111, 68, 0.5);\">good</span> <span title=\"0.020\" style=\"background-color: rgba(174, 9, 38, 0.5);\">,</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">ageable</span> <span title=\"0.871\" style=\"background-color: rgba(48, 162, 85, 0.5);\">bottlings</span> <span title=\"0.043\" style=\"background-color: rgba(184, 18, 38, 0.5);\">from</span> <span title=\"0.050\" style=\"background-color: rgba(188, 22, 38, 0.5);\">the</span> <span title=\"-0.242\" style=\"background-color: rgba(165, 0, 38, 0.5);\">likes</span> <span title=\"0.058\" style=\"background-color: rgba(192, 26, 38, 0.5);\">of</span> <span title=\"0.198\" style=\"background-color: rgba(242, 106, 65, 0.5);\">xxmaj</span> <span title=\"0.238\" style=\"background-color: rgba(247, 131, 77, 0.5);\">sequoia</span> <span title=\"-0.039\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span> <span title=\"-0.083\" style=\"background-color: rgba(165, 0, 38, 0.5);\">grove</span> <span title=\"-0.055\" style=\"background-color: rgba(165, 0, 38, 0.5);\">and</span> <span title=\"-0.296\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxmaj</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BILtDGEqxPLn",
        "colab_type": "text"
      },
      "source": [
        "Run justify prediction from custom code, giving the top 5 tokens contributing to the decision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo2cBWE5OxQt",
        "colab_type": "code",
        "outputId": "dcaa5bf9-f671-4e44-cdeb-9bbf6248424f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "learn.justify.predict(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category US - California,\n",
              " tensor(0.9997),\n",
              " [('ageable', tensor(1., device='cuda:0')),\n",
              "  ('bottlings', tensor(0.8707, device='cuda:0')),\n",
              "  ('wants', tensor(0.8477, device='cuda:0')),\n",
              "  ('currants', tensor(0.7486, device='cuda:0')),\n",
              "  ('fine', tensor(0.6192, device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDdQ9osaCTTu",
        "colab_type": "text"
      },
      "source": [
        "This is immediately making the prediction more interpretable and is allowing the user to learn a little about Claifornian wine, suggesting currant flavours are indicative of this region. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGGbZTmUxWPJ",
        "colab_type": "text"
      },
      "source": [
        "Next, give the closest 3 categories to the one chosen and display the 5 top tokens for each of those classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqwYmAjADlI3",
        "colab_type": "code",
        "outputId": "178c1433-2b60-4407-b95b-3fe321c7271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "learn.justify.nearest_cat(text, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('France - Bordeaux',\n",
              "  tensor(0.0002),\n",
              "  [('morisoli', tensor(1., device='cuda:0')),\n",
              "   ('vineyard', tensor(0.2879, device='cuda:0')),\n",
              "   ('xxmaj', tensor(0.1686, device='cuda:0')),\n",
              "   ('likes', tensor(0.1164, device='cuda:0')),\n",
              "   ('oak', tensor(0.0696, device='cuda:0'))]),\n",
              " ('US - Washington',\n",
              "  tensor(2.0093e-05),\n",
              "  [('morisoli', tensor(1., device='cuda:0')),\n",
              "   ('vineyard', tensor(0.1704, device='cuda:0')),\n",
              "   ('currants', tensor(0.1175, device='cuda:0')),\n",
              "   ('xxmaj', tensor(0.1147, device='cuda:0')),\n",
              "   ('acidic', tensor(0.1033, device='cuda:0'))]),\n",
              " ('France - Southwest France',\n",
              "  tensor(1.6345e-05),\n",
              "  [('morisoli', tensor(1., device='cuda:0')),\n",
              "   ('vineyard', tensor(0.4456, device='cuda:0')),\n",
              "   ('grove', tensor(0.4151, device='cuda:0')),\n",
              "   ('xxmaj', tensor(0.3054, device='cuda:0')),\n",
              "   ('cabernet', tensor(0.1486, device='cuda:0'))])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2GjTe1ZCtYH",
        "colab_type": "text"
      },
      "source": [
        "Interestingly, Morisoli is highly activating for these classes. This might flag an error in our model (which is another useful consequence of interpretability) or might also suggest aa similaarity which is often referenced in wine descriptions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8FlIuN2-wKw",
        "colab_type": "text"
      },
      "source": [
        "# Context in RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOBipOloDOjp",
        "colab_type": "text"
      },
      "source": [
        "It is clear to see that the above interpretation methods add significant value to these prediction models, allowing jsutification, error flagging and the potentail for education. \n",
        "\n",
        "However we also see that single tokens/words are not always that instructive and might bely the full context with which that word is used.\n",
        "\n",
        "The below code investigates this further,particularly looking at how substituting various words throughout the description influences intrinsic attribution of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ZluBZ_-1MC",
        "colab_type": "code",
        "outputId": "d4491683-9cc3-4bca-bd34-dd68a1fd7fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        }
      },
      "source": [
        "data_clas.show_batch(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this very fine xxmaj cabernet wants a little time in the cellar . xxmaj right now , it 's tight in tannins , with some acidic bitterness in the finish . xxmaj the flavors are of black currants and smoky new oak . xxmaj the xxmaj morisoli xxmaj vineyard has been home to very good , ageable bottlings from the likes of xxmaj sequoia xxmaj grove and xxmaj</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos a terrific example of xxmaj corbières terroir at an unbeatable price . xxmaj the wine , a traditional xxmaj rhône - style blend of xxmaj syrah , xxmaj grenache and xxmaj carignan , is so loaded with aromas and flavors of the surrounding garrigue you might think that they xxunk in a bouquet garni during maturation . xxmaj sage , rosemary , menthol , thyme and bay leaves all</td>\n",
              "      <td>France - Languedoc-Roussillon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos a massive wine , decadent and splendid , and a worthy followup to the near - perfect 2008 . xxmaj densely packed in fruit , it explodes in blackberries , cassis , dark chocolate , minerals and sweet , toasty new oak . xxmaj that richness is lifted to brilliance by the tannic structure , which is world class . xxmaj so deliciously approachable , it 's drinkable now</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj hat xxmaj trick is the best of the best of xxmaj morgan 's estate vineyard , which is in the chilliest northwestern part of the xxmaj highlands . xxmaj acidity stars , giving the wine a brilliant crispness that 's so clean and fine . xxmaj barrel fermented in one - third new xxmaj french oak , the wine is incredibly rich and leesy . xxmaj the terroir</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this is a new single - vineyard bottling for xxmaj goldeneye , grown in the cooler xxmaj deep xxmaj end western part of the valley . xxmaj it 's a feral kind of xxmaj pinot . xxmaj not for it the tame fruit of warmer climates . xxmaj this one brims with wild berries : cherries , raspberries , something animal and leathery , and mossy tastes of</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj columbia xxmaj crest makes a limited number of single vineyard reserves . xxmaj this xxmaj zinfandel comes from what is emerging as the best site for that grape in xxmaj washington . xxmaj bright , tart , and full of sappy raspberry and red fruits , this young , ageworthy xxmaj zin has great penetration and punch . xxmaj in style , it is closest to classic xxmaj</td>\n",
              "      <td>US - Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj you do n't have to age this wine — xxmaj jarvis did it for you , holding it back more than five years before release , which is a very expensive proposition for a winery . xxmaj it 's a splendid xxmaj cabernet , with the tannins soft and velvety . xxmaj the blackberry and black currant fruit flavors are as fresh and vibrant as the day the</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this is almost pure xxmaj cab , with the addition of just 2 % xxmaj malbec . xxmaj solidly in the firm , muscular , polished style of winemaker xxmaj holly xxmaj turner , this is a substantial effort that will need to be decanted if you are going to drink it any time soon . xxmaj black cherry , cassis and blue plum are swathed in milk</td>\n",
              "      <td>US - Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos a line up of xxunk 's 2010 and 2011 xxmaj pinot xxmaj noirs make a bold statement for xxmaj finger xxmaj lakes xxmaj pinot , but the regular label 2011 is drinking particularly well now . xxmaj lifted violet and berry notes are intoxicating on this spicy , deftly balanced wine . xxmaj rich , ripe black - cherry and raspberry flavors blend into a liquid silk on the</td>\n",
              "      <td>US - New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this xxmaj cabernet is a blend of estate and purchased fruit . xxmaj in a successful year , it rivals xxmaj stag 's xxmaj leap 's best wines , including xxmaj cask 23 , and 2008 was a very successful year . xxmaj blended with 2 % xxmaj merlot , and aged in lots of new xxmaj french oak , the wine is , in a word ,</td>\n",
              "      <td>US - California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L560Tsqw_GmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = data_clas.train_ds[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqV83pTWB1Kv",
        "colab_type": "code",
        "outputId": "adcf0ca8-a3b1-4f58-cd0c-93928abaa3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "learn.predict(test_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category Italy - Sicily & Sardinia,\n",
              " tensor(16),\n",
              " tensor([6.8727e-07, 5.2921e-07, 1.8685e-06, 2.1200e-06, 3.8360e-06, 3.6119e-06,\n",
              "         4.8331e-06, 2.3117e-06, 6.2219e-07, 1.6509e-06, 1.5259e-06, 5.8269e-02,\n",
              "         1.3068e-02, 6.9895e-02, 1.3347e-01, 3.2327e-02, 4.2442e-01, 1.6917e-01,\n",
              "         8.7599e-02, 7.9983e-03, 3.5779e-03, 1.2926e-05, 2.6908e-05, 3.6262e-05,\n",
              "         9.7286e-06, 6.1159e-05, 4.6936e-05]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcBk5xfBDxqn",
        "colab_type": "text"
      },
      "source": [
        "show intrinsic attribution with respect the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmbFe8nd_kWX",
        "colab_type": "code",
        "outputId": "7fff8471-a8de-4f2f-d6bc-2ea8c78e24a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "txt_ci.show_intrinsic_attention(test_text, 16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"font-family: monospace;\"><span title=\"-0.008\" style=\"background-color: rgba(165, 0, 38, 0.5);\">xxbos</span> <span title=\"0.039\" style=\"background-color: rgba(182, 16, 38, 0.5);\">xxbos</span> <span title=\"0.017\" style=\"background-color: rgba(172, 7, 38, 0.5);\">xxmaj</span> <span title=\"0.180\" style=\"background-color: rgba(238, 97, 61, 0.5);\">aromas</span> <span title=\"-0.002\" style=\"background-color: rgba(165, 0, 38, 0.5);\">include</span> <span title=\"0.267\" style=\"background-color: rgba(250, 152, 86, 0.5);\">tropical</span> <span title=\"0.078\" style=\"background-color: rgba(202, 35, 38, 0.5);\">fruit</span> <span title=\"0.210\" style=\"background-color: rgba(244, 114, 69, 0.5);\">,</span> <span title=\"0.540\" style=\"background-color: rgba(239, 248, 169, 0.5);\">broom</span> <span title=\"0.304\" style=\"background-color: rgba(253, 174, 97, 0.5);\">,</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">brimstone</span> <span title=\"0.080\" style=\"background-color: rgba(204, 37, 38, 0.5);\">and</span> <span title=\"0.101\" style=\"background-color: rgba(214, 47, 38, 0.5);\">dried</span> <span title=\"0.171\" style=\"background-color: rgba(234, 89, 58, 0.5);\">herb</span> <span title=\"0.053\" style=\"background-color: rgba(190, 24, 38, 0.5);\">.</span> <span title=\"0.078\" style=\"background-color: rgba(202, 35, 38, 0.5);\">xxmaj</span> <span title=\"0.050\" style=\"background-color: rgba(188, 22, 38, 0.5);\">the</span> <span title=\"0.001\" style=\"background-color: rgba(165, 0, 38, 0.5);\">palate</span> <span title=\"0.117\" style=\"background-color: rgba(220, 58, 43, 0.5);\">is</span> <span title=\"0.083\" style=\"background-color: rgba(206, 39, 38, 0.5);\">n&#x27;t</span> <span title=\"-0.204\" style=\"background-color: rgba(165, 0, 38, 0.5);\">overly</span> <span title=\"-0.086\" style=\"background-color: rgba(165, 0, 38, 0.5);\">expressive</span> <span title=\"-0.011\" style=\"background-color: rgba(165, 0, 38, 0.5);\">,</span> <span title=\"-0.103\" style=\"background-color: rgba(165, 0, 38, 0.5);\">offering</span> <span title=\"-0.134\" style=\"background-color: rgba(165, 0, 38, 0.5);\">unripened</span> <span title=\"-0.236\" style=\"background-color: rgba(165, 0, 38, 0.5);\">apple</span> <span title=\"0.025\" style=\"background-color: rgba(176, 11, 38, 0.5);\">,</span> <span title=\"-0.004\" style=\"background-color: rgba(165, 0, 38, 0.5);\">citrus</span> <span title=\"0.014\" style=\"background-color: rgba(170, 5, 38, 0.5);\">and</span> <span title=\"-0.025\" style=\"background-color: rgba(165, 0, 38, 0.5);\">dried</span> <span title=\"-0.096\" style=\"background-color: rgba(165, 0, 38, 0.5);\">sage</span> <span title=\"0.046\" style=\"background-color: rgba(186, 20, 38, 0.5);\">alongside</span> <span title=\"-0.131\" style=\"background-color: rgba(165, 0, 38, 0.5);\">brisk</span> <span title=\"-0.011\" style=\"background-color: rgba(165, 0, 38, 0.5);\">acidity</span> <span title=\"0.006\" style=\"background-color: rgba(166, 1, 38, 0.5);\">.</span></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txbBunFdB-9Y",
        "colab_type": "code",
        "outputId": "90ef07df-9bb6-4b65-b986-151435015194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "learn.justify.predict(test_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category Italy - Sicily & Sardinia,\n",
              " tensor(0.4244),\n",
              " [('brimstone', tensor(1., device='cuda:0')),\n",
              "  ('broom', tensor(0.5403, device='cuda:0')),\n",
              "  (',', tensor(0.3044, device='cuda:0')),\n",
              "  ('tropical', tensor(0.2672, device='cuda:0')),\n",
              "  (',', tensor(0.2104, device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W5Bx28LCEJ3",
        "colab_type": "text"
      },
      "source": [
        "selection of commas as top tokens suggests that it is more to do with the sentence they are a part of than the tokens themselves.\n",
        "\n",
        "**Note from later** - this appears to be symptomatic of effective overfitting in interpretation, I will be investigating using code from this paper https://arxiv.org/pdf/1910.13294.pdf to solve thisin future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlBuLjeDBsx4",
        "colab_type": "text"
      },
      "source": [
        "**Testing Influence**\n",
        "\n",
        "swap each top 5 words for xxpad token to test true root of influence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTbREE7BryF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_swapped = 'xxbos xxmaj aromas include xxpad fruit xxpad xxpad xxpad xxpad and dried herb . xxmaj the palate is n\\'t overly expressive , offering unripened apple , citrus and dried sage alongside brisk acidity .'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5VxoaTCfDt",
        "colab_type": "code",
        "outputId": "27630941-8fc7-4663-b30b-7240b6a96ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "learn.justify.predict(text_swapped)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category Italy - Northeastern Italy,\n",
              " tensor(0.4318),\n",
              " [('unripened', tensor(1., device='cuda:0')),\n",
              "  ('herb', tensor(0.6547, device='cuda:0')),\n",
              "  ('expressive', tensor(0.5916, device='cuda:0')),\n",
              "  ('sage', tensor(0.5082, device='cuda:0')),\n",
              "  ('brisk', tensor(0.4526, device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN0u6sQXEmFB",
        "colab_type": "text"
      },
      "source": [
        "This changes the prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhF2RMWHCiMB",
        "colab_type": "code",
        "outputId": "6bbfa456-951b-4ad9-d6ea-4e623e852bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "learn.justify.nearest_cat(text_swapped, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('US - California',\n",
              "  tensor(0.1457),\n",
              "  [('palate', tensor(1., device='cuda:0')),\n",
              "   ('citrus', tensor(0.9526, device='cuda:0')),\n",
              "   ('acidity', tensor(0.7178, device='cuda:0')),\n",
              "   ('xxmaj', tensor(0.6662, device='cuda:0')),\n",
              "   ('include', tensor(0.6642, device='cuda:0'))]),\n",
              " ('Italy - Veneto',\n",
              "  tensor(0.0822),\n",
              "  [('xxpad', tensor(1., device='cuda:0')),\n",
              "   ('overly', tensor(0.5603, device='cuda:0')),\n",
              "   ('xxwrep', tensor(0.3942, device='cuda:0')),\n",
              "   ('xxpad', tensor(0.3844, device='cuda:0')),\n",
              "   ('4', tensor(0.3140, device='cuda:0'))]),\n",
              " ('Italy - Piedmont',\n",
              "  tensor(0.0796),\n",
              "  [('xxpad', tensor(1., device='cuda:0')),\n",
              "   ('alongside', tensor(0.5470, device='cuda:0')),\n",
              "   ('brisk', tensor(0.3425, device='cuda:0')),\n",
              "   ('xxwrep', tensor(0.3101, device='cuda:0')),\n",
              "   ('citrus', tensor(0.3065, device='cuda:0'))])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SYXQIzfDqWJ",
        "colab_type": "text"
      },
      "source": [
        "Changing single words does change predictions above but context is clearly important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv_UG3imD2uW",
        "colab_type": "text"
      },
      "source": [
        "# Apples and Oranges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QL6gEUgD8DC",
        "colab_type": "text"
      },
      "source": [
        "With original swapped text below, prediction is Northeastern Italy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdQTiJsnC3Qr",
        "colab_type": "code",
        "outputId": "c641b3a5-1547-4135-fab8-a7d3395f2868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "text_swapped = 'xxbos xxmaj aromas include xxpad fruit xxpad xxpad xxpad xxpad and dried herb . xxmaj the palate is n\\'t overly expressive , offering unripened apple , citrus and dried sage alongside brisk acidity .'\n",
        "\n",
        "learn.justify.predict(text_swapped)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category Italy - Northeastern Italy,\n",
              " tensor(0.4318),\n",
              " [('unripened', tensor(1., device='cuda:0')),\n",
              "  ('herb', tensor(0.6547, device='cuda:0')),\n",
              "  ('expressive', tensor(0.5916, device='cuda:0')),\n",
              "  ('sage', tensor(0.5082, device='cuda:0')),\n",
              "  ('brisk', tensor(0.4526, device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSRw2NbCEKBM",
        "colab_type": "text"
      },
      "source": [
        "'unripened' is the most expressive token according to this. However, that doesn't seem to be that descriptive as different unripened fruits will have very different flavours.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIi89TWKEHXZ",
        "colab_type": "code",
        "outputId": "68202958-f2e4-4c6a-d254-9de47a90c0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "text_swapped_orange = 'xxbos xxmaj aromas include xxpad fruit xxpad xxpad xxpad xxpad and dried herb . xxmaj the palate is n\\'t overly expressive , offering unripened oranges , citrus and dried sage alongside brisk acidity .'\n",
        "learn.justify.predict(text_swapped_orange)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
            "/pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category Italy - Piedmont,\n",
              " tensor(0.2259),\n",
              " [('xxpad', tensor(1., device='cuda:0')),\n",
              "  ('alongside', tensor(0.8027, device='cuda:0')),\n",
              "  ('brisk', tensor(0.5092, device='cuda:0')),\n",
              "  ('sage', tensor(0.4898, device='cuda:0')),\n",
              "  ('xxwrep', tensor(0.3120, device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T9FgLZpFZ7L",
        "colab_type": "text"
      },
      "source": [
        "This has changed the prediction, despite Apple not showing up as a key word before.\n",
        "\n",
        "Conclusion - current RNN interpretation methods will show the contribution of a single word, but it is the context of that word which is most important."
      ]
    }
  ]
}